# ğŸš€ LLM Backend éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†å¦‚ä½•åœ¨ä¸åŒç¯å¢ƒä¸­éƒ¨ç½² LLM Backend æœåŠ¡ã€‚

## ğŸ“‹ éƒ¨ç½²æ¦‚è¿°

LLM Backend æ”¯æŒå¤šç§éƒ¨ç½²æ–¹å¼ï¼š
- **å¼€å‘ç¯å¢ƒéƒ¨ç½²** - æœ¬åœ°å¼€å‘å’Œæµ‹è¯•
- **ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²** - æœåŠ¡å™¨ç”Ÿäº§ç¯å¢ƒ
- **Docker å®¹å™¨éƒ¨ç½²** - å®¹å™¨åŒ–éƒ¨ç½²
- **äº‘å¹³å°éƒ¨ç½²** - AWSã€é˜¿é‡Œäº‘ç­‰äº‘å¹³å°

## ğŸ”§ ç¯å¢ƒè¦æ±‚

### ç¡¬ä»¶è¦æ±‚

| é…ç½®çº§åˆ« | CPU | å†…å­˜ | å­˜å‚¨ | é€‚ç”¨åœºæ™¯ |
|----------|-----|------|------|----------|
| æœ€ä½é…ç½® | 4æ ¸ | 8GB | 20GB | å¼€å‘æµ‹è¯• |
| æ¨èé…ç½® | 8æ ¸ | 16GB | 50GB | å°è§„æ¨¡ç”Ÿäº§ |
| é«˜æ€§èƒ½é…ç½® | 16æ ¸ | 32GB | 100GB | å¤§è§„æ¨¡ç”Ÿäº§ |

### è½¯ä»¶è¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 20.04+), macOS (10.15+), Windows 10+
- **Go**: 1.21 æˆ–æ›´é«˜ç‰ˆæœ¬
- **Node.js**: 18.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- **Git**: 2.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- **CMake**: 3.15 æˆ–æ›´é«˜ç‰ˆæœ¬ (ç¼–è¯‘ llama.cpp)

## ğŸ  å¼€å‘ç¯å¢ƒéƒ¨ç½²

### 1. å…‹éš†é¡¹ç›®

```bash
git clone <repository-url>
cd llm
```

### 2. ç¼–è¯‘ llama.cpp

```bash
cd llama.cpp
mkdir build && cd build

# åŸºç¡€ç¼–è¯‘
cmake ..

# å¯ç”¨ GPU æ”¯æŒ (å¯é€‰)
cmake .. -DLLAMA_CUBLAS=ON

# å¯ç”¨ Metal æ”¯æŒ (macOS)
cmake .. -DLLAMA_METAL=ON

# ç¼–è¯‘
make -j$(nproc)
cd ../..
```

### 3. å‡†å¤‡æ¨¡å‹æ–‡ä»¶

```bash
mkdir -p models

# ä¸‹è½½æ¨èæ¨¡å‹ (ç¤ºä¾‹)
# æ³¨æ„: å®é™…ä¸‹è½½é“¾æ¥éœ€è¦æ ¹æ®æ¨¡å‹æä¾›æ–¹è·å–

# æ ¼å¼è½¬æ¢ä¸“ç”¨æ¨¡å‹ (1.3GB)
wget -O models/deepseek-coder-1.3b-instruct-q4_k_m.gguf \
  "https://example.com/deepseek-coder-1.3b-instruct-q4_k_m.gguf"

# é€šç”¨å¯¹è¯æ¨¡å‹ (4.2GB)
wget -O models/qwen2-7b-instruct-q4_k_m.gguf \
  "https://example.com/qwen2-7b-instruct-q4_k_m.gguf"

# éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
ls -lh models/
```

### 4. å¯åŠ¨åç«¯æœåŠ¡

```bash
cd backend

# å®‰è£…ä¾èµ–
go mod tidy

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
go run main.go

# æˆ–ç¼–è¯‘åè¿è¡Œ
go build -o llm-server main.go
./llm-server
```

### 5. å¯åŠ¨å‰ç«¯æœåŠ¡

```bash
cd frontend

# å®‰è£…ä¾èµ–
npm install

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev

# æ„å»ºç”Ÿäº§ç‰ˆæœ¬
npm run build
```

### 6. éªŒè¯éƒ¨ç½²

```bash
# æ£€æŸ¥åç«¯å¥åº·çŠ¶æ€
curl http://localhost:8080/health

# æ£€æŸ¥å‰ç«¯è®¿é—®
open http://localhost:5173
```

## ğŸ­ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### 1. ç³»ç»Ÿå‡†å¤‡

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install -y build-essential cmake git curl

# CentOS/RHEL
sudo yum groupinstall -y "Development Tools"
sudo yum install -y cmake git curl

# åˆ›å»ºä¸“ç”¨ç”¨æˆ·
sudo useradd -m -s /bin/bash llm
sudo usermod -aG sudo llm
```

### 2. å®‰è£… Go

```bash
# ä¸‹è½½å¹¶å®‰è£… Go
wget https://go.dev/dl/go1.21.5.linux-amd64.tar.gz
sudo tar -C /usr/local -xzf go1.21.5.linux-amd64.tar.gz

# è®¾ç½®ç¯å¢ƒå˜é‡
echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc
source ~/.bashrc
```

### 3. å®‰è£… Node.js

```bash
# ä½¿ç”¨ NodeSource ä»“åº“
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs

# æˆ–ä½¿ç”¨ nvm
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash
source ~/.bashrc
nvm install 18
nvm use 18
```

### 4. éƒ¨ç½²åº”ç”¨

```bash
# åˆ‡æ¢åˆ° llm ç”¨æˆ·
sudo su - llm

# å…‹éš†é¡¹ç›®åˆ°ç”Ÿäº§ç›®å½•
git clone <repository-url> /opt/llm
cd /opt/llm

# ç¼–è¯‘ llama.cpp
cd llama.cpp
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j$(nproc)
cd ../..

# æ„å»ºåç«¯
cd backend
go mod tidy
go build -o llm-server main.go
cd ..

# æ„å»ºå‰ç«¯
cd frontend
npm install
npm run build
cd ..
```

### 5. é…ç½®ç³»ç»ŸæœåŠ¡

åˆ›å»º systemd æœåŠ¡æ–‡ä»¶ï¼š

```bash
sudo tee /etc/systemd/system/llm-backend.service > /dev/null <<EOF
[Unit]
Description=LLM Backend Service
After=network.target

[Service]
Type=simple
User=llm
Group=llm
WorkingDirectory=/opt/llm/backend
ExecStart=/opt/llm/backend/llm-server
Restart=always
RestartSec=5
Environment=LOG_LEVEL=info
Environment=PORT=8080

[Install]
WantedBy=multi-user.target
EOF

# å¯ç”¨å¹¶å¯åŠ¨æœåŠ¡
sudo systemctl daemon-reload
sudo systemctl enable llm-backend
sudo systemctl start llm-backend
sudo systemctl status llm-backend
```

### 6. é…ç½® Nginx

```bash
# å®‰è£… Nginx
sudo apt install -y nginx

# åˆ›å»ºé…ç½®æ–‡ä»¶
sudo tee /etc/nginx/sites-available/llm-backend > /dev/null <<EOF
server {
    listen 80;
    server_name your-domain.com;

    # å‰ç«¯é™æ€æ–‡ä»¶
    location / {
        root /opt/llm/frontend/dist;
        try_files \$uri \$uri/ /index.html;
    }

    # åç«¯ API
    location /api/ {
        proxy_pass http://localhost:8080;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
    }

    # å¥åº·æ£€æŸ¥
    location /health {
        proxy_pass http://localhost:8080;
    }
}
EOF

# å¯ç”¨ç«™ç‚¹
sudo ln -s /etc/nginx/sites-available/llm-backend /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx
```

## ğŸ³ Docker éƒ¨ç½²

### 1. åˆ›å»º Dockerfile

```dockerfile
# å¤šé˜¶æ®µæ„å»º
FROM golang:1.21-alpine AS backend-builder

WORKDIR /app
COPY backend/ .
RUN go mod tidy && go build -o llm-server main.go

FROM node:18-alpine AS frontend-builder

WORKDIR /app
COPY frontend/ .
RUN npm install && npm run build

FROM ubuntu:22.04

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    curl \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN useradd -m -s /bin/bash llm

# å¤åˆ¶ç¼–è¯‘å¥½çš„æ–‡ä»¶
COPY --from=backend-builder /app/llm-server /usr/local/bin/
COPY --from=frontend-builder /app/dist /var/www/html/
COPY llama.cpp/build/bin/llama-server /usr/local/bin/

# åˆ›å»ºå¿…è¦ç›®å½•
RUN mkdir -p /opt/llm/models /opt/llm/logs
RUN chown -R llm:llm /opt/llm

USER llm
WORKDIR /opt/llm

EXPOSE 8080

CMD ["llm-server"]
```

### 2. åˆ›å»º docker-compose.yml

```yaml
version: '3.8'

services:
  llm-backend:
    build: .
    ports:
      - "8080:8080"
    volumes:
      - ./models:/opt/llm/models:ro
      - ./logs:/opt/llm/logs
    environment:
      - LOG_LEVEL=info
      - PORT=8080
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - llm-backend
    restart: unless-stopped
```

### 3. éƒ¨ç½²å‘½ä»¤

```bash
# æ„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

## â˜ï¸ äº‘å¹³å°éƒ¨ç½²

### AWS éƒ¨ç½²

1. **åˆ›å»º EC2 å®ä¾‹**
```bash
# é€‰æ‹© Ubuntu 22.04 LTS
# å®ä¾‹ç±»å‹: t3.large æˆ–æ›´é«˜
# å­˜å‚¨: 50GB GP3
# å®‰å…¨ç»„: å¼€æ”¾ 80, 443, 22 ç«¯å£
```

2. **é…ç½® ELB è´Ÿè½½å‡è¡¡å™¨**
```bash
# åˆ›å»º Application Load Balancer
# é…ç½®å¥åº·æ£€æŸ¥: /health
# é…ç½® SSL è¯ä¹¦
```

3. **ä½¿ç”¨ RDS æ•°æ®åº“** (å¯é€‰)
```bash
# åˆ›å»º RDS MySQL å®ä¾‹
# é…ç½®æ•°æ®åº“è¿æ¥
```

### é˜¿é‡Œäº‘éƒ¨ç½²

1. **åˆ›å»º ECS å®ä¾‹**
```bash
# é€‰æ‹© Ubuntu 20.04
# è§„æ ¼: ecs.c6.2xlarge æˆ–æ›´é«˜
# ç³»ç»Ÿç›˜: 100GB ESSD
```

2. **é…ç½® SLB è´Ÿè½½å‡è¡¡**
```bash
# åˆ›å»ºåº”ç”¨å‹è´Ÿè½½å‡è¡¡
# é…ç½®ç›‘å¬å™¨å’Œåç«¯æœåŠ¡å™¨
```

## ğŸ”’ å®‰å…¨é…ç½®

### 1. é˜²ç«å¢™é…ç½®

```bash
# Ubuntu UFW
sudo ufw allow ssh
sudo ufw allow 80
sudo ufw allow 443
sudo ufw enable

# CentOS firewalld
sudo firewall-cmd --permanent --add-service=ssh
sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https
sudo firewall-cmd --reload
```

### 2. SSL è¯ä¹¦é…ç½®

```bash
# ä½¿ç”¨ Let's Encrypt
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx -d your-domain.com
```

### 3. å®‰å…¨åŠ å›º

```bash
# ç¦ç”¨ root ç™»å½•
sudo sed -i 's/PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config

# é…ç½®å¯†é’¥è®¤è¯
ssh-keygen -t rsa -b 4096
ssh-copy-id user@server

# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y
```

## ğŸ“Š ç›‘æ§å’Œç»´æŠ¤

### 1. æ—¥å¿—ç®¡ç†

```bash
# é…ç½®æ—¥å¿—è½®è½¬
sudo tee /etc/logrotate.d/llm-backend > /dev/null <<EOF
/opt/llm/logs/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    copytruncate
}
EOF
```

### 2. æ€§èƒ½ç›‘æ§

```bash
# å®‰è£…ç›‘æ§å·¥å…·
sudo apt install htop iotop nethogs

# ç›‘æ§ç³»ç»Ÿèµ„æº
htop
iotop
nethogs
```

### 3. å¤‡ä»½ç­–ç•¥

```bash
# åˆ›å»ºå¤‡ä»½è„šæœ¬
#!/bin/bash
BACKUP_DIR="/backup/llm-$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

# å¤‡ä»½æ•°æ®åº“
cp /opt/llm/backend/database.db $BACKUP_DIR/

# å¤‡ä»½é…ç½®æ–‡ä»¶
cp -r /opt/llm/backend/config $BACKUP_DIR/

# å‹ç¼©å¤‡ä»½
tar -czf $BACKUP_DIR.tar.gz $BACKUP_DIR
rm -rf $BACKUP_DIR
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹å¯åŠ¨å¤±è´¥**
```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
ls -lh models/
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/app.log
```

2. **ç«¯å£å ç”¨**
```bash
# æŸ¥çœ‹ç«¯å£ä½¿ç”¨
sudo netstat -tlnp | grep :8080
# æ€æ­»å ç”¨è¿›ç¨‹
sudo kill -9 <PID>
```

3. **æƒé™é—®é¢˜**
```bash
# ä¿®å¤æ–‡ä»¶æƒé™
sudo chown -R llm:llm /opt/llm
sudo chmod +x /opt/llm/backend/llm-server
```

---

**éƒ¨ç½²å®Œæˆåï¼Œè¯·è®¿é—®åº”ç”¨å¹¶è¿›è¡ŒåŠŸèƒ½æµ‹è¯•ï¼** ğŸ‰
