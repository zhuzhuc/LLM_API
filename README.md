# è½»é‡çº§å¤§è¯­è¨€æ¨¡å‹ API æœåŠ¡

[![Go Version](https://img.shields.io/badge/Go-1.21+-blue.svg)](https://golang.org)
[![Vue Version](https://img.shields.io/badge/Vue-3.0+-green.svg)](https://vuejs.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Build Status](https://img.shields.io/badge/Build-Passing-brightgreen.svg)]()

ä¸€ä¸ªåŸºäº Go + Vue 3 çš„è½»é‡çº§å¤§è¯­è¨€æ¨¡å‹ API æœåŠ¡ï¼Œé›†æˆå¤šä¸ªå¼€æº LLM æ¨¡å‹ï¼Œæä¾›æ–‡ä»¶æ ¼å¼è½¬æ¢ã€ä½œä¸šæ‰¹æ”¹ã€å­—å¹•å¤„ç†ç­‰ AI åŠŸèƒ½ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **å¤šæ¨¡å‹æ”¯æŒ** - é›†æˆ Qwenã€DeepSeekã€Yiã€Mistral ç­‰å¤šä¸ªè½»é‡çº§æ¨¡å‹
- **åŠ¨æ€æ¨¡å‹ç®¡ç†** - æ”¯æŒæ¨¡å‹çš„åŠ¨æ€å¯åŠ¨ã€åœæ­¢å’Œåˆ‡æ¢ï¼ŒèŠ‚çœç³»ç»Ÿèµ„æº
- **ä¸“ç”¨ä»»åŠ¡å¤„ç†** - æ–‡ä»¶æ ¼å¼è½¬æ¢ã€ä½œä¸šæ‰¹æ”¹ã€å­—å¹•å¤„ç†ç­‰ä¸“é—¨ä¼˜åŒ–çš„åŠŸèƒ½
- **ç®€å•è®¤è¯ç³»ç»Ÿ** - JWT è®¤è¯ã€Token ç®¡ç†ã€ç”¨æˆ·æƒé™æ§åˆ¶
- **é«˜æ€§èƒ½æ¶æ„** - Go é«˜æ€§èƒ½ API æœåŠ¡ + llama.cpp æ¨ç†å¼•æ“
- **ç°ä»£åŒ–å‰ç«¯** - Vue 3 + Element Plus + Vite å“åº”å¼ Web ç•Œé¢
- **ç›‘æ§ä¸æ—¥å¿—** - å®Œæ•´çš„è¯·æ±‚è¿½è¸ªå’Œæ€§èƒ½ç›‘æ§
- **å®Œå–„æµ‹è¯•** - æä¾›å¤šç§æµ‹è¯•è„šæœ¬å’Œå·¥å…·

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

### æŠ€æœ¯æ ˆ
- **åç«¯ API æœåŠ¡**: Go 1.21+ (Gin æ¡†æ¶)
- **å‰ç«¯ç•Œé¢**: Vue 3 + Element Plus + Vite
- **æ¨¡å‹æ¨ç†**: llama.cpp (GGUF æ ¼å¼)
- **è®¤è¯ç³»ç»Ÿ**: JWT
- **æ•°æ®åº“**: SQLite

### æœåŠ¡æ¶æ„
```
Frontend (Vue 3) â†’ Go API Server â†’ llama.cpp
       :5173            :8080        :8081-8085
                           â†“
                      SQLite DB
```

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### æœ€ä½é…ç½®
- **CPU**: 8 æ ¸å¿ƒä»¥ä¸Š
- **å†…å­˜**: 16GB RAM
- **å­˜å‚¨**: 20GB å¯ç”¨ç©ºé—´
- **æ“ä½œç³»ç»Ÿ**: macOS 10.15+ / Ubuntu 20.04+ / CentOS 8+
- **è½¯ä»¶ä¾èµ–**: Go 1.21+, Node.js 16+

### æ¨èé…ç½®
- **CPU**: 16 æ ¸å¿ƒä»¥ä¸Š (Intel/AMD/Apple Silicon)
- **å†…å­˜**: 32GB RAM
- **å­˜å‚¨**: 50GB SSD
- **ç½‘ç»œ**: åƒå…†ç½‘ç»œ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone <your-repo-url>
cd LLM_API

# å®‰è£…ç³»ç»Ÿä¾èµ– (Ubuntu/Debian)
sudo apt update
sudo apt install -y build-essential git wget curl nodejs npm

# å®‰è£…ç³»ç»Ÿä¾èµ– (macOS)
brew install git wget curl node
```

### 2. è®¾ç½® llama.cpp

```bash
# è¿è¡Œè‡ªåŠ¨åŒ–è®¾ç½®è„šæœ¬
chmod +x setup-llama-cpp.sh
./setup-llama-cpp.sh
```

### 3. ä¸‹è½½æ¨¡å‹

```bash
# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ° models/ ç›®å½•
# é¡¹ç›®å·²åŒ…å«å¤šä¸ªé¢„ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶
ls models/
```

### 4. æ„å»ºå’Œå¯åŠ¨æœåŠ¡

#### å¯åŠ¨åç«¯æœåŠ¡ (Go)
```bash
cd backend
go mod tidy
go run main.go
# æœåŠ¡è¿è¡Œåœ¨ http://localhost:8080
```

#### å¯åŠ¨å‰ç«¯æœåŠ¡ (Vue 3)
```bash
cd frontend
npm install
npm run dev
# å‰ç«¯è¿è¡Œåœ¨ http://localhost:5173
```

### 5. æµ‹è¯•éƒ¨ç½²

```bash
# æµ‹è¯• Go API æœåŠ¡
cd backend
./test_all_apis.sh

# æµ‹è¯•å•ä¸ª API
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", "model": "qwen2-7b-instruct-q4_k_m"}'
```

## ğŸ”§ é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½®

é¡¹ç›®æ”¯æŒå¤šç§ CPU ä¼˜åŒ–æ¨¡å‹ï¼š

| æ¨¡å‹ | å‚æ•°è§„æ¨¡ | ä¸­æ–‡èƒ½åŠ› | å†…å­˜éœ€æ±‚ | æ¨èç”¨é€” |
|------|----------|----------|----------|----------|
| Qwen2-7B-Instruct | 7B | â­â­â­â­â­ | ~8GB | ä¸­æ–‡å¯¹è¯ã€æ–‡æ¡£å¤„ç† |
| Yi-9B-Chat | 9B | â­â­â­â­â­ | ~10GB | å¤šä»»åŠ¡ã€åˆ›ä½œ |
| DeepSeek-Coder-6.7B | 6.7B | â­â­â­â­ | ~7GB | ä»£ç ç”Ÿæˆã€ç¼–ç¨‹ |
| Mistral-7B-Instruct | 7B | â­â­â­ | ~8GB | è‹±æ–‡ä»»åŠ¡ã€æ¨ç† |

### æ€§èƒ½è°ƒä¼˜

#### Go æœåŠ¡é…ç½®
```bash
# è®¾ç½® Go è¿è¡Œæ—¶å‚æ•°
export GOMAXPROCS=12  # å»ºè®®è®¾ç½®ä¸º CPU æ ¸å¿ƒæ•°
export GOGC=100       # GC è§¦å‘ç™¾åˆ†æ¯”
```



#### llama.cpp çº¿ç¨‹é…ç½®
```bash
# åœ¨å¯åŠ¨ llama-server æ—¶è®¾ç½®çº¿ç¨‹æ•°
./llama-cpp/llama-server -m models/qwen2-7b-instruct-q4_k_m.gguf -t 12
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ
- **CPU**: Intel i7-12700K (12æ ¸20çº¿ç¨‹)
- **å†…å­˜**: 32GB DDR4-3200
- **æ¨¡å‹**: Qwen2-7B-Instruct Q4_K_M

### æ€§èƒ½æŒ‡æ ‡
| ä»»åŠ¡ç±»å‹ | è¾“å…¥é•¿åº¦ | è¾“å‡ºé•¿åº¦ | å“åº”æ—¶é—´ | ååé‡ |
|----------|----------|----------|----------|--------|
| ç®€å•é—®ç­” | 50 tokens | 100 tokens | 4-6ç§’ | ~20 tokens/s |
| æ–‡æ¡£æ‘˜è¦ | 500 tokens | 200 tokens | 12-15ç§’ | ~15 tokens/s |
| ä»£ç ç”Ÿæˆ | 100 tokens | 300 tokens | 18-25ç§’ | ~12 tokens/s |

## ğŸ”Œ API æ¥å£

### Go API æœåŠ¡ (ç«¯å£ 8080)

#### èŠå¤©æ¥å£
```bash
POST /api/chat
Content-Type: application/json

{
  "message": "ä½ å¥½ï¼Œè¯·å¸®æˆ‘å†™ä¸€ä¸ª Python å‡½æ•°",
  "model": "qwen2-7b-instruct-q4_k_m",
  "temperature": 0.7,
  "max_tokens": 500
}
```

#### æ¨¡å‹ç®¡ç†
```bash
# è·å–å¯ç”¨æ¨¡å‹
GET /api/models

# è·å–æ¨¡å‹çŠ¶æ€
GET /api/models/status

# åˆ‡æ¢æ¨¡å‹
POST /api/models/switch
{
  "model": "qwen2-7b-instruct-q4_k_m"
}
```

#### æ–‡ä»¶å¤„ç†
```bash
# æ–‡ä»¶ä¸Šä¼ å’Œå¤„ç†
POST /api/upload
Content-Type: multipart/form-data

# æ–‡ä»¶æ ¼å¼è½¬æ¢
POST /api/convert
```

#### è®¤è¯æ¥å£
```bash
# ç”¨æˆ·æ³¨å†Œ
POST /api/auth/register

# ç”¨æˆ·ç™»å½•
POST /api/auth/login

# è·å–ç”¨æˆ·ä¿¡æ¯
GET /api/auth/profile
Authorization: Bearer <token>
```

## ğŸ” å®‰å…¨é…ç½®

### Keycloak é›†æˆ

1. **å®‰è£… Keycloak**
```bash
# Docker æ–¹å¼
docker run -p 8080:8080 -e KEYCLOAK_ADMIN=admin -e KEYCLOAK_ADMIN_PASSWORD=admin quay.io/keycloak/keycloak:latest start-dev
```

2. **é…ç½® Realm å’Œ Client**
- åˆ›å»º Realm: `llm-realm`
- åˆ›å»º Client: `llm-app`
- é…ç½®ç”¨æˆ·è§’è‰²: `USER`, `ADMIN`

3. **æ›´æ–°é…ç½®**
```yaml
keycloak:
  auth-server-url: http://localhost:8080/auth
  realm: llm-realm
  resource: llm-app
```

## ğŸ³ Docker éƒ¨ç½²

é¡¹ç›®æä¾›äº†å®Œæ•´çš„ Docker éƒ¨ç½²æ–¹æ¡ˆï¼ŒåŒ…å«æ‰€æœ‰æœåŠ¡ç»„ä»¶ã€‚

### ä½¿ç”¨ Docker Compose (æ¨è)
```bash
# ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

### æœåŠ¡ç«¯å£æ˜ å°„
- **å‰ç«¯æœåŠ¡**: http://localhost:5173
- **Go API æœåŠ¡**: http://localhost:8080
- **llama.cpp æœåŠ¡**: http://localhost:8081-8085

### è‡ªå®šä¹‰ Dockerfile

#### Go æœåŠ¡ Dockerfile
```dockerfile
FROM golang:1.21-alpine AS builder
WORKDIR /app
COPY backend/ .
RUN go mod tidy && go build -o main .

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=builder /app/main .
EXPOSE 8080
CMD ["./main"]
```

#### å‰ç«¯ Dockerfile
```dockerfile
FROM node:18-alpine AS builder
WORKDIR /app
COPY frontend/package*.json ./
RUN npm install
COPY frontend/ .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
EXPOSE 80
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Go æœåŠ¡å¯åŠ¨å¤±è´¥**
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
lsof -i :8080
# æ£€æŸ¥ Go ç‰ˆæœ¬
go version
# é‡æ–°ç¼–è¯‘
cd backend && go build -o main .
```

2. **å†…å­˜ä¸è¶³**
```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–å‡å°‘å¹¶å‘æ•°
```

3. **æ¨¡å‹åŠ è½½å¤±è´¥**
```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
ls -la models/
# éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
file models/*.gguf
# æ£€æŸ¥ llama-server è¿›ç¨‹
ps aux | grep llama-server
```

4. **å‰ç«¯æ„å»ºå¤±è´¥**
```bash
# æ¸…ç†ä¾èµ–é‡æ–°å®‰è£…
cd frontend
rm -rf node_modules package-lock.json
npm install
```

5. **llama.cpp ç¼–è¯‘å¤±è´¥**
```bash
# æ¸…ç†é‡æ–°ç¼–è¯‘
cd llama-cpp
make clean
make -j$(nproc)
```

### æ—¥å¿—åˆ†æ
```bash
# æŸ¥çœ‹ Go æœåŠ¡æ—¥å¿—
tail -f logs/http.log

# æŸ¥çœ‹ llama-server æ—¥å¿—
tail -f logs/llama-server.log
```

## ğŸ“ˆ ç›‘æ§å’Œè¿ç»´

### å¥åº·æ£€æŸ¥
```bash
# Go API æœåŠ¡å¥åº·æ£€æŸ¥
curl http://localhost:8080/api/health

# å‰ç«¯æœåŠ¡æ£€æŸ¥
curl http://localhost:5173
```

### æ€§èƒ½ç›‘æ§
```bash
# æ£€æŸ¥æ‰€æœ‰æœåŠ¡è¿›ç¨‹
ps aux | grep -E "(main|java|node)"

# Go æœåŠ¡å†…å­˜ä½¿ç”¨
ps aux | grep main

# æ¨¡å‹æ¨ç†ç»Ÿè®¡
curl http://localhost:8080/api/models/status
```

### æœåŠ¡ç®¡ç†è„šæœ¬
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
./start-llm-service.sh

# åœæ­¢æ‰€æœ‰æœåŠ¡
./stop-llm-service.sh

# é‡å¯æœåŠ¡
./stop-llm-service.sh && ./start-llm-service.sh
```

## ğŸš€ ç”Ÿäº§éƒ¨ç½²å»ºè®®

1. **ç¡¬ä»¶é…ç½®**
   - ä½¿ç”¨ SSD å­˜å‚¨æ¨¡å‹æ–‡ä»¶
   - é…ç½®è¶³å¤Ÿçš„ RAM (æ¨¡å‹å¤§å° Ã— 1.5)
   - é€‰æ‹©é«˜é¢‘ CPU (æ¨è 16+ æ ¸å¿ƒ)

2. **ç³»ç»Ÿä¼˜åŒ–**
   - å…³é—­ä¸å¿…è¦çš„ç³»ç»ŸæœåŠ¡
   - è®¾ç½® CPU æ€§èƒ½æ¨¡å¼
   - ä¼˜åŒ–ç½‘ç»œé…ç½®å’Œæ–‡ä»¶æè¿°ç¬¦é™åˆ¶

3. **åº”ç”¨é…ç½®**
   - ä½¿ç”¨ç”Ÿäº§çº§æ•°æ®åº“ (MySQL/PostgreSQL)
   - é…ç½® Nginx åå‘ä»£ç†å’Œè´Ÿè½½å‡è¡¡
   - è®¾ç½®æ—¥å¿—è½®è½¬å’Œç›‘æ§å‘Šè­¦
   - é…ç½® HTTPS å’Œ SSL è¯ä¹¦

4. **æœåŠ¡éƒ¨ç½²**
   - ä½¿ç”¨ Docker Compose æˆ– Kubernetes
   - é…ç½®æœåŠ¡è‡ªåŠ¨é‡å¯å’Œå¥åº·æ£€æŸ¥
   - è®¾ç½®èµ„æºé™åˆ¶å’Œç¯å¢ƒå˜é‡

5. **å®‰å…¨åŠ å›º**
   - å¯ç”¨ JWT è®¤è¯å’Œæˆæƒ
   - é…ç½®é˜²ç«å¢™å’Œç½‘ç»œå®‰å…¨ç»„
   - å®šæœŸæ›´æ–°ä¾èµ–å’Œå®‰å…¨è¡¥ä¸
   - è®¾ç½® API é™æµå’Œè®¿é—®æ§åˆ¶

## ğŸ“š å‚è€ƒèµ„æº

### æ ¸å¿ƒæŠ€æœ¯æ–‡æ¡£
- [Go å®˜æ–¹æ–‡æ¡£](https://golang.org/doc/)
- [Gin Web æ¡†æ¶](https://gin-gonic.com/docs/)
- [Vue 3 å®˜æ–¹æ–‡æ¡£](https://vuejs.org/guide/)
- [Element Plus ç»„ä»¶åº“](https://element-plus.org/)
- [Spring Boot å®˜æ–¹æ–‡æ¡£](https://spring.io/projects/spring-boot)

### AI æ¨¡å‹ç›¸å…³
- [llama.cpp å®˜æ–¹æ–‡æ¡£](https://github.com/ggerganov/llama.cpp)
- [Qwen2 æ¨¡å‹æ–‡æ¡£](https://huggingface.co/Qwen)
- [GGUF æ ¼å¼è¯´æ˜](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md)

### è®¤è¯å’Œå®‰å…¨
- [JWT è®¤è¯æŒ‡å—](https://jwt.io/introduction)

### éƒ¨ç½²å’Œè¿ç»´
- [Docker å®˜æ–¹æ–‡æ¡£](https://docs.docker.com/)
- [Docker Compose æŒ‡å—](https://docs.docker.com/compose/)

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. åˆ›å»º Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚
